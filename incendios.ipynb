{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos cada uno de los archivos, guardandolos en sus DataFrames respectivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incendios forestales y daños, causas, ocurrencia\n",
    "df_ocurrencia_incendios = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"ocurrencia_incendios_region.csv\")) # Cleaned\n",
    "df_causas_incendios = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"causas_incendios.csv\")) # Cleaned\n",
    "df_danos_superficie = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"danos_superficie (ha).csv\")) # Cleaned\n",
    "df_incendios = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"incendios_filtrados.csv\")) # Depende de si lo utilizamos o no\n",
    "\n",
    "# Daños por comuna\n",
    "df_danos_comuna_2014_2015 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_comunas (2014 - 2015).csv\"))\n",
    "df_danos_comuna_2015_2016 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_comunas (2015 - 2016).csv\"))\n",
    "df_danos_comuna_2016_2017 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_comunas (2016 - 2017).csv\"))\n",
    "df_danos_comuna_2017_2018 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_comunas (2017 - 2018).csv\"))\n",
    "df_danos_comuna_2018_2019 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_comunas (2018 - 2019).csv\"))\n",
    "df_danos_comuna_2019_2020 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_comunas (2019 - 2020).csv\"))\n",
    "df_danos_comuna_2020_2021 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_comunas (2020 - 2021).csv\"))\n",
    "df_danos_comuna_2021_2022 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_comunas (2021 - 2022).csv\"))\n",
    "\n",
    "# Daños por mes\n",
    "df_danos_mes_2014_2015 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_mes (2014 - 2015).csv\")) # Cleaned\n",
    "df_danos_mes_2015_2016 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_mes (2015 - 2016).csv\")) # Cleaned\n",
    "df_danos_mes_2016_2017 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_mes (2016 - 2017).csv\")) # Cleaned\n",
    "df_danos_mes_2017_2018 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_mes (2017 - 2018).csv\")) # Cleaned\n",
    "df_danos_mes_2018_2019 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_mes (2018 - 2019).csv\")) # Cleaned\n",
    "df_danos_mes_2019_2020 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_mes (2019 - 2020).csv\")) # Cleaned\n",
    "df_danos_mes_2020_2021 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_mes (2020 - 2021).csv\")) # Cleaned\n",
    "df_danos_mes_2021_2022 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"dano_hectareas_mes (2021 - 2022).csv\")) # Cleaned\n",
    "\n",
    "# Ocurrencia por mes\n",
    "df_ocurrencia_mes_2018_2019 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"Ocurrencia_mes_2019.csv\"))\n",
    "df_ocurrencia_mes_2019_2020 = pd.read_csv(os.path.join(\"data\", \"raw\", \"Incendios\", \"Ocurrencia_mes_2020.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame: Ocurrencia de incendios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe: df_ocurrencia_incendios\n",
    "\n",
    "# Reemplazamos los valores nulos por 0\n",
    "df_ocurrencia_incendios = df_ocurrencia_incendios.fillna(0)\n",
    "print(f\"Hay {len(df_ocurrencia_incendios[df_ocurrencia_incendios.isna().any(axis=1)])} filas con valores nulos\")\n",
    "\n",
    "# Aproximamos todos los valores a enteros excepto la primera columna\n",
    "\n",
    "for i in range(1, len(df_ocurrencia_incendios.columns)):\n",
    "    df_ocurrencia_incendios[df_ocurrencia_incendios.columns[i]] = df_ocurrencia_incendios[df_ocurrencia_incendios.columns[i]].astype(int)\n",
    "\n",
    "# Tomamos todas las columnas excepto la primera\n",
    "data = df_ocurrencia_incendios[df_ocurrencia_incendios.columns[1:]]\n",
    "\n",
    "# Sumamos todas las filas y las guardamos en una nueva columna llamada \"TOTAL\"\n",
    "df_ocurrencia_incendios[\"TOTAL\"] = data.sum(axis=1)\n",
    "\n",
    "# Guardamos el dataframe en un archivo csv con el mismo nombre, en caso de que ya exista lo sobreescribe\n",
    "df_ocurrencia_incendios.to_csv(os.path.join(\"data\", \"ocurrencia_incendios\", \"ocurrencia_incendios_region.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame: Causas Incendios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe: df_causas_incendios\n",
    "\n",
    "# Reemplazamos los valores nulos por 0\n",
    "df_causas_incendios = df_causas_incendios.fillna(0)\n",
    "\n",
    "# Tomamos los años como índice\n",
    "anhos = df_causas_incendios.columns[1:]\n",
    "anhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos las columnas por filas\n",
    "df_causas_incendios_tr = df_causas_incendios.transpose()\n",
    "df_causas_incendios_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos las primeras 3 filas y las hacemos el header\n",
    "df_causas_incendios_tr.columns = df_causas_incendios_tr.iloc[0]\n",
    "df_causas_incendios_tr.columns.name = None\n",
    "df_causas_incendios_tr = df_causas_incendios_tr.iloc[1:]\n",
    "\n",
    "# Añadimos una columna con los años en la primera posición y eliminamos los índices\n",
    "df_causas_incendios_tr.insert(0, \"AÑO\", anhos)\n",
    "df_causas_incendios_tr = df_causas_incendios_tr.reset_index(drop=True)\n",
    "\n",
    "# Reemplazamos los valores nulos por 0\n",
    "df_causas_incendios_tr = df_causas_incendios_tr.fillna(0)\n",
    "\n",
    "# Reemplazamos comas por puntos\n",
    "df_causas_incendios_tr = df_causas_incendios_tr.replace(\",\", \".\", regex=True)\n",
    "\n",
    "df_causas_incendios_tr.to_csv(os.path.join(\"data\", \"causas_incendios\", \"causas_incendios.csv\"), index=False)\n",
    "\n",
    "df_causas_incendios_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame: Daños Superficie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe: df_danos_superficie\n",
    "\n",
    "# Reeemplazamos los valores nulos por 0\n",
    "df_danos_superficie_limpio = df_danos_superficie.fillna(0)\n",
    "\n",
    "# Reemplazamos comas por puntos\n",
    "df_danos_superficie_limpio = df_danos_superficie_limpio.replace(\",\", \".\", regex=True)\n",
    "\n",
    "# Reemplazamos los valores con punto a float y los demás a int  \n",
    "for i in range(1, len(df_danos_superficie_limpio.columns)):\n",
    "    df_danos_superficie_limpio[df_danos_superficie_limpio.columns[i]] = df_danos_superficie_limpio[df_danos_superficie_limpio.columns[i]].astype(float).round(2)\n",
    "\n",
    "# Tomamos todas las columnas excepto la primera\n",
    "data = df_danos_superficie_limpio[df_danos_superficie_limpio.columns[1:]]\n",
    "df_danos_superficie_limpio[\"TOTAL\"] = data.sum(axis=1).round()\n",
    "\n",
    "# Guardamos el dataframe en un archivo csv con el mismo nombre, en caso de que ya exista lo sobreescribe\n",
    "df_danos_superficie_limpio.to_csv(os.path.join(\"data\", \"danos_superficies_hectareas\", \"danos_superficies_limpio.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame: Incendios (Data general del gobierno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe: df_incendios\n",
    "\n",
    "# Analizamos los valores nulos\n",
    "df_incendios[df_incendios.isna().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame: Daños hectareas (Comunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_danos_comuna_2014_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza_comuna(dfs, anho1, anho2):\n",
    "    dfs_g = dfs.copy()\n",
    "    dfs_g = dfs_g.fillna(0.0)\n",
    "    dfs_g.drop(columns=[\"TOTAL OTRAS SUPERFICIES\", \"TOTAL\", \"TOTAL PINO INSIGNE\", \"TOTAL  FORESTAL \", \"TOTAL.1\"], inplace=True)\n",
    "    dfs_g = dfs_g.replace(r'[. ]', '', regex=True)\n",
    "    dfs_g = dfs_g.replace(\",\", \".\", regex=True)\n",
    "    dfs_g = dfs_g.replace(\" \", \"0.0\", regex=True)\n",
    "    for i in range(2, (len(dfs_g.columns)-1)):\n",
    "        dfs_g[dfs_g.columns[i]] = dfs_g[dfs_g.columns[i]].astype(float).round(2)\n",
    "    dfs_g.to_csv(os.path.join(\"data\", \"danos_hectareas_comunas\", f\"danos_hectareas_comunas ({anho1} - {anho2}).csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lista_df_comuna = [df_danos_comuna_2014_2015, df_danos_comuna_2015_2016, df_danos_comuna_2016_2017,\n",
    "                   df_danos_comuna_2017_2018, df_danos_comuna_2018_2019, df_danos_comuna_2019_2020, \n",
    "                   df_danos_comuna_2020_2021, df_danos_comuna_2021_2022]\n",
    "\n",
    "anho1 = 2014\n",
    "anho2 = 2015\n",
    "for df in lista_df_comuna:\n",
    "    limpieza_comuna(df, anho1, anho2)\n",
    "    print(f\"Limpiado {anho1} - {anho2}\")\n",
    "    anho1 += 1\n",
    "    anho2 += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leemos el csv limpio\n",
    "df_danos_comuna_2014_2015_limpio = pd.read_csv(os.path.join(\"data\", \"danos_hectareas_comunas\", \"danos_hectareas_comunas (2014 - 2015).csv\"))\n",
    "df_danos_comuna_2014_2015_limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame: Daños hectareas mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza_mes(dfs, anho1, anho2):\n",
    "    dfs_g = dfs.copy()\n",
    "    dfs_g = dfs.fillna(0.0)\n",
    "    dfs_g = dfs_g.replace(r'[. ]', '', regex=True)\n",
    "    dfs_g = dfs_g.replace(\",\", \".\", regex=True)\n",
    "    dfs_g = dfs_g.replace(\" \", \"0.0\", regex=True)\n",
    "    for i in range(1, len(dfs.columns)):\n",
    "        dfs_g[dfs_g.columns[i]] = dfs_g[dfs_g.columns[i]].astype(float).round(2)\n",
    "    data = dfs_g[dfs_g.columns[1:]]\n",
    "    dfs[\"TOTAL\"] = data.sum(axis=1)\n",
    "    dfs_g.to_csv(os.path.join(\"data\", \"danos_hectareas_meses\", f\"dano_hectareas_mes ({anho1} - {anho2}).csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_df_mes = [df_danos_mes_2014_2015, df_danos_mes_2015_2016, df_danos_mes_2016_2017,\n",
    "                 df_danos_mes_2017_2018, df_danos_mes_2018_2019, df_danos_mes_2019_2020, \n",
    "                 df_danos_mes_2020_2021, df_danos_mes_2021_2022]\n",
    "anho1 = 2014\n",
    "anho2 = 2015\n",
    "for i in range(len(lista_df_mes)):\n",
    "    limpieza_mes(lista_df_mes[i], anho1, anho2)\n",
    "    anho1 += 1\n",
    "    anho2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos el csv limpio\n",
    "df_danos_mes_2016_2017 = pd.read_csv(os.path.join(\"data\", \"danos_hectareas_meses\", \"dano_hectareas_mes (2016 - 2017).csv\"))\n",
    "df_danos_mes_2016_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los datos de daños por mes\n",
    "regiones = df_danos_mes_2016_2017.columns[1:]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Daños por mes (2016 - 2017)\")\n",
    "plt.xlabel(\"Mes\")\n",
    "plt.ylabel(\"Daños (ha)\")\n",
    "for i in range(1, len(df_danos_mes_2016_2017.columns)):\n",
    "    sns.lineplot(data=df_danos_mes_2016_2017, x=\"MES\", y=df_danos_mes_2016_2017.columns[i], label=df_danos_mes_2016_2017.columns[i])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame: Ocurrencia de incendios (Mes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función para limpiar los datos de ocurrencia por mes\n",
    "def limpieza_ocurrencia_mes(dfs, anho1, anho2):\n",
    "    dfs_g = dfs.copy()\n",
    "    dfs_g = dfs_g.fillna(0)\n",
    "    for i in range(1, len(dfs.columns)):\n",
    "        dfs_g[dfs_g.columns[i]] = dfs_g[dfs_g.columns[i]].astype(int)\n",
    "    dfs_g.drop(columns=[\"TOTAL\"], inplace=True)\n",
    "    data = dfs_g[dfs_g.columns[1:]]\n",
    "    dfs_g[\"TOTAL\"] = data.sum(axis=1)\n",
    "    dfs_g.to_csv(os.path.join(\"data\", \"ocurrencia_mes\", f\"ocurrencia_mes_{anho1}_{anho2}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos los datos de ocurrencia por mes\n",
    "lista_df_ocurrencia_mes = [df_ocurrencia_mes_2018_2019, df_ocurrencia_mes_2019_2020]\n",
    "anho1 = 2018\n",
    "anho2 = 2019\n",
    "\n",
    "for i in range(len(lista_df_ocurrencia_mes)):\n",
    "    limpieza_ocurrencia_mes(lista_df_ocurrencia_mes[i], anho1, anho2)\n",
    "    anho1 += 1\n",
    "    anho2 += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
